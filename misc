def clean_search_words(ser,count=10000):
    #0、 去除网址
#     pattern = re.compile('[\w\s:]*(//)?[\w\s\.\?/&=~]*(\.\s*com|\.\s*cn)[\w\s\.\?/&=~]*')
#     pattern = re.compile('http[s]www\s*\.[\w\s\.\?/&=~]*(\.cn|\.com)')
    pattern = re.compile('(https?[\sa-zA-z0-9.=&?/:]+|[a-zA-z0-9.=&?\/:\s]+\.(com|cn))')
    ser = ser.astype(str).map(lambda x: re.sub(pattern,'',x,count=count))    
    #1、将字段合并的分割符号替换为，
    pattern = re.compile('(~+|<seg>)')
    ser = ser.astype(str).map(lambda x: re.sub(pattern,',',x,count=count))
    
    #2、所有的中文标点符号和英文其他标段符号转换为英文逗号
    pattern = re.compile('[\u3002\uff1b\uff0c\uff1a\u201c\u201d\uff08\uff09\u3001\uff1f\u300a\u300b!?;]')
    ser= ser.map(lambda x: re.sub(pattern,',',x, count=count))
    
    #3、去除空格
    pattern = re.compile('\s+([a-zA-z0-9])')
    ser = ser.map(lambda x: re.sub(pattern,',\\1',x, count=count)) #英文空格换成,
    pattern = re.compile('\s+([\u4e00-\u9fa5])')
    ser = ser.map(lambda x: re.sub(pattern,'',x,count=count)) #中文空格直接去除
    #3、特殊字符
#     pattern = re.compile('[\+\-\\//\"_-|@#￥$%&\*\{\}\[\]<>^~【】!！=\.\:\(\)\u3000]')
#     ser = ser.map(lambda x: re.sub(pattern,'',x,count=count))

    #3、只保留汉字和[a-zA-z0-9,+-]
    pattern = re.compile('[^\u4e00-\u9fa5\-\+,a-zA-Z0-9]')
    ser = ser.map(lambda x:re.sub(pattern,'',x,count=count))
    #4、去除无意义的连续数字和字母(todo 将huaweimate30pro,oppor9pro这种提出来)
#     pattern = re.compile('[a-zA-z0-9]{12,}')
#     ser = ser.map(lambda x: re.sub(pattern,'',x, count=count))
    
    #5. 去除多余的，
    pattern = re.compile(',+')
    ser =ser.map(lambda x: re.sub(pattern,',',x, count=count))

    return ser

def filter_3sigma(df):
    mean = df.mean()
    std = df.std()
    low = mean-3*std
    high = mean + 3*std
    df = df[(df>=low)&(df<=high)]
    return df
